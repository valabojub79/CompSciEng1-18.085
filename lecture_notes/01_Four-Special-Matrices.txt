Matrix facets to consider:
	1. Sparsity
	2. Diagonality
	3. Symmetry
	4. Constant diagonals (Toeplitz)
	5. Invertibility
	6. Triangularity (closely related to sparsity)

When seeking to solve a linear system, the question of invertibility arises.
The naive way to check for invertibility is to ask about nonzero determinant.
Strang dislikes determinants (loss of meaning, difficult to compute?).

A more logical way to think about solving a system and about determinants:
A more straightforward approach can be to use row reduction (Guassian elimination?).
In using elimination, we seek to make the matrix upper triangular.
That is, we want to "clean out" (make zero) entries beneath the diagonal.
To do so, move down the matrix one row at a time.
For each row after the top, make one additional rightward column a 0.
That is, for second row, make first entry zero. For third row, two zeros, etc.
To accomplish that, multiply scale above row by constant factor.
Choose the factor such that +/- current row and row above it makes target entry a 0.
The value in row directly above target entry is called the "pivot."
Thus, the diagonal entries of resulting upper triangular are the "pivots."
Once the matrix is upper triangular, determinant is simply product of the pivots.
Thus, the matrix is invertible if all diagonal entries are nonzero when it's upper triangular.
This accords with intuition of over-/under-specified system if we consider backpropagation/substitution to solve.

Erosion of invertibility:
"Periodic" or "circulant" matrix structure, in which constant diagonal "wraps" implies invertibility.
Summing all rows may result in all-zeros row?
This means that there's a solution in the null space (i.e., there's a vector that the matrix multiplies to give 0-vector).
Existence of nonzero solution in null space means that it's not invertible.
Invertibility is clear given that C^-1 * C * u = C^-1 * 0 --> I * u = 0 --> u = 0.
* Key point to take away: only solution to Cu=0 is u=0 if C is invertible.

